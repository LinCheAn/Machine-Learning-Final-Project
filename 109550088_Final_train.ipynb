{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: auc = 0.5873615394326317\n",
      "Fold 1: auc = 0.5848479830444022\n",
      "Fold 2: auc = 0.5922739327255239\n",
      "Fold 3: auc = 0.5992151528776978\n",
      "Fold 4: auc = 0.5920760904094672\n",
      "Average auc = 0.59115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "auc_list = []\n",
    "test_pred = []\n",
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "kf = GroupKFold(n_splits = 5)\n",
    "for fold, (idx_train, idx_vaild) in enumerate(kf.split(train, train.failure, train.product_code)):\n",
    "    X_train = train.iloc[idx_train][test.columns]\n",
    "    X_vaild = train.iloc[idx_vaild][test.columns]\n",
    "    y_train = train.iloc[idx_train].failure\n",
    "    y_vaild = train.iloc[idx_vaild].failure \n",
    "    X_test = test.copy()\n",
    "\n",
    "    #add a column which recode the missing of measurement_5\n",
    "    X_train['m_5_missing'] = X_train.measurement_5.isna()\n",
    "    X_vaild['m_5_missing'] = X_vaild.measurement_5.isna()\n",
    "    X_test['m_5_missing'] = X_test.measurement_5.isna()\n",
    "    \n",
    "    #impute the missing block\n",
    "    features = []\n",
    "    for feature in X_train.columns:\n",
    "        if feature == 'loading' or feature.startswith('measurement'):\n",
    "            features.append(feature)\n",
    "    imputer = SimpleImputer(strategy = \"most_frequent\")\n",
    "    imputer.fit(X_train[features])\n",
    "    for df in [X_train, X_vaild, X_test]:\n",
    "        df[features] = imputer.transform(df[features])\n",
    "    \n",
    "    #encode the attributes\n",
    "    encode_attributes = ['attribute_0', 'attribute_1']  \n",
    "    for df in [X_train, X_vaild, X_test]:\n",
    "        code_list = []\n",
    "        dfA_list = df['attribute_0'].values\n",
    "        dfB_list = df['attribute_1'].values\n",
    "        for itemidx in range(len(dfA_list)):\n",
    "            if dfA_list[itemidx] == 'material_5' or dfB_list[itemidx] == 'material_5':\n",
    "                code_list.append(True)\n",
    "            else:\n",
    "                code_list.append(False)\n",
    "        df['material_5'] = code_list\n",
    "    for df in [X_train, X_vaild, X_test]:\n",
    "        code_list = []\n",
    "        dfA_list = df['attribute_0'].values\n",
    "        dfB_list = df['attribute_1'].values\n",
    "        for itemidx in range(len(dfA_list)):\n",
    "            if dfA_list[itemidx] == 'material_7' or dfB_list[itemidx] == 'material_7':\n",
    "                code_list.append(True)\n",
    "            else:\n",
    "                code_list.append(False)\n",
    "        df['material_7'] = code_list\n",
    "        df.drop(columns = encode_attributes, inplace = True)\n",
    "    \n",
    "    #select features to fit model\n",
    "    feature_selc = ['loading', 'material_5', 'material_7', 'measurement_2', 'measurement_10', 'measurement_17', 'm_5_missing']\n",
    "    #model = RandomForestRegressor(n_estimators = 150, max_depth = 10, min_samples_leaf = 100, n_jobs = -1, random_state = 1)\n",
    "    #model = AdaBoostClassifier(base_estimator = None, n_estimators = 150, learning_rate = 0.075, algorithm = 'SAMME.R', random_state = None)\n",
    "    #model = RandomForestClassifier(n_estimators = 250, max_depth = 8, min_samples_leaf = 100, n_jobs = -1, random_state = 1)\n",
    "    #model = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C = 0.001, solver = 'liblinear', random_state = 1))\n",
    "    model = make_pipeline(StandardScaler(), LogisticRegression(penalty = 'l2', C = 0.000005, solver = 'saga', random_state = 0))\n",
    "    model.fit(X_train[feature_selc], y_train)\n",
    "    y_vaild_pred = model.predict_proba(X_vaild[feature_selc])[ : , 1]\n",
    "    score = roc_auc_score(y_vaild, y_vaild_pred)\n",
    "    print(f\"Fold {fold}: auc = {score}\")\n",
    "    auc_list.append(score)\n",
    "    if(fold < 4 and fold > 0):\n",
    "        test_pred.append(model.predict_proba(X_test[feature_selc])[ : , 1])\n",
    "        #save models\n",
    "        joblib.dump(model, f\"model_{fold}\")\n",
    "\n",
    "# Show overall score\n",
    "print(f\"Average auc = {sum(auc_list) / len(auc_list):.5f}\")\n",
    "\n",
    "#write result into csv\n",
    "submission = pd.DataFrame({'id': test.index, 'failure': sum(test_pred)/len(test_pred)})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If above code can't reproduce the result, please download models and run this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "test_pred = []\n",
    "X_test = test.copy()\n",
    "#add a column which recode the missing of measurement_5\n",
    "X_test['m_5_missing'] = X_test.measurement_5.isna()\n",
    "#impute the missing block\n",
    "features = []\n",
    "for feature in X_train.columns:\n",
    "    if feature == 'loading' or feature.startswith('measurement'):\n",
    "        features.append(feature)\n",
    "imputer = SimpleImputer(strategy = \"most_frequent\")\n",
    "imputer.fit(X_train[features])\n",
    "for df in [X_test]:\n",
    "    df[features] = imputer.transform(df[features])\n",
    "\n",
    "#encode the attributes\n",
    "encode_attributes = ['attribute_0', 'attribute_1']  \n",
    "for df in [X_test]:\n",
    "    code_list = []\n",
    "    dfA_list = df['attribute_0'].values\n",
    "    dfB_list = df['attribute_1'].values\n",
    "    for itemidx in range(len(dfA_list)):\n",
    "        if dfA_list[itemidx] == 'material_5' or dfB_list[itemidx] == 'material_5':\n",
    "            code_list.append(True)\n",
    "        else:\n",
    "            code_list.append(False)\n",
    "    df['material_5'] = code_list\n",
    "for df in [X_test]:\n",
    "    code_list = []\n",
    "    dfA_list = df['attribute_0'].values\n",
    "    dfB_list = df['attribute_1'].values\n",
    "    for itemidx in range(len(dfA_list)):\n",
    "        if dfA_list[itemidx] == 'material_7' or dfB_list[itemidx] == 'material_7':\n",
    "            code_list.append(True)\n",
    "        else:\n",
    "            code_list.append(False)\n",
    "    df['material_7'] = code_list\n",
    "    df.drop(columns = encode_attributes, inplace = True)\n",
    "\n",
    "#select features to fit model\n",
    "feature_selc = ['loading', 'material_5', 'material_7', 'measurement_2', 'measurement_10', 'measurement_17', 'm_5_missing']\n",
    "for fold in range(1, 4):\n",
    "    model = joblib.load(f\"model_{fold}\")\n",
    "    test_pred.append(model.predict_proba(X_test[feature_selc])[ : , 1])\n",
    "    \n",
    "#write result into csv\n",
    "submission = pd.DataFrame({'id': test.index, 'failure': sum(test_pred)/len(test_pred)})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "016d4e6fe71ff4162b1262bc18d77bbb4306e50207a2d93deee16585bc6dcbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
